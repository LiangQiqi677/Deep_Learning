{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T07:47:47.612275Z",
     "start_time": "2020-08-14T07:47:45.562120Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "path = \"./车辆分类数据集/bus/bus001.jpg\"\n",
    "train_features = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "test_features = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "\n",
    "# 处理客车数据，总共218张，前153张为训练集，后65张为测试集\n",
    "pic_num = 0\n",
    "for filename in os.listdir(\"./车辆分类数据集/bus/\"): \n",
    "    pic_num = pic_num + 1\n",
    "    path = \"./车辆分类数据集/bus/\"+ filename\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    if pic_num <= 153:\n",
    "        train_features = torch.cat((train_features,img), dim=0)\n",
    "    else:\n",
    "        test_features = torch.cat((test_features,img), dim=0)\n",
    "\n",
    "# 处理汽车数据，总共779张，前545张为训练集，后234张为测试集\n",
    "pic_num = 0\n",
    "for filename in os.listdir(\"./车辆分类数据集/car/\"): \n",
    "    pic_num = pic_num + 1\n",
    "    path = \"./车辆分类数据集/car/\"+ filename\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    if pic_num <= 545:\n",
    "        train_features = torch.cat((train_features,img), dim=0)\n",
    "    else:\n",
    "        test_features = torch.cat((test_features,img), dim=0)\n",
    "\n",
    "# 处理货车数据，总共360张，前252张为训练集，后108张为测试集\n",
    "pic_num = 0\n",
    "for filename in os.listdir(\"./车辆分类数据集/truck/\"): \n",
    "    pic_num = pic_num + 1\n",
    "    path = \"./车辆分类数据集/truck/\"+ filename\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    if pic_num <= 252:\n",
    "        train_features = torch.cat((train_features,img), dim=0)\n",
    "    else:\n",
    "        test_features = torch.cat((test_features,img), dim=0)\n",
    "\n",
    "train_features = train_features.permute(0,3,2,1)\n",
    "test_features = test_features.permute(0,3,2,1)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "# =================== 训练集标签 =================== #\n",
    "train_labels = torch.zeros(154).long()\n",
    "train_labels = torch.cat((train_labels,torch.ones(545).long()), dim=0)\n",
    "train_labels = torch.cat((train_labels,torch.ones(252).long()+1), dim=0)\n",
    "print(train_labels.shape)\n",
    "\n",
    "# =================== 测试集标签 =================== #\n",
    "test_labels = torch.zeros(66).long()\n",
    "test_labels = torch.cat((test_labels,torch.ones(234).long()), dim=0)\n",
    "test_labels = torch.cat((test_labels,torch.ones(108).long()+1), dim=0)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T07:47:54.673012Z",
     "start_time": "2020-08-14T07:47:54.268108Z"
    }
   },
   "outputs": [],
   "source": [
    "#自定义卷积层\n",
    "\n",
    "def corr2d(X, K):\n",
    "    \"\"\"\n",
    "    X: 输入, shape(batch_size, H, W)\n",
    "    K: 卷积核,shape(k_h, k_w)\n",
    "    \"\"\"\n",
    "    batch_size, H, W = X.shape\n",
    "    #print(\"\\ncorr2d:\")\n",
    "    #print(X.shape)\n",
    "    #print(batch_size, H, W)\n",
    "    k_h, k_w = K.shape\n",
    "    #初始化结果矩阵\n",
    "    Y = torch.zeros((batch_size, H-k_h+1, W-k_w+1))\n",
    "    for i in range(Y.shape[1]):\n",
    "        for j in range(Y.shape[2]):\n",
    "            Y[:,i,j] = (X[: , i:i+k_h , j:j+k_w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    \"\"\"\n",
    "    X: 输入, shape(batch_size, C_in, H, W)\n",
    "    K: 卷积核, shape(C_in, k_h, k_w)\n",
    "    return: 输出, shape(batch_size, H_out, W_out)\n",
    "    \"\"\"\n",
    "    #print(\"\\ncorr2d_multi_in\")\n",
    "    #print(X.shape) #torch.Size([32, 3, 100, 100])\n",
    "    #print(K.shape) #torch.Size([32, 3, 3])\n",
    "    res = corr2d(X[: , 0 , : , : ], K[0, : , : ])\n",
    "    for i in range(1, X.shape[1]):\n",
    "        res += corr2d(X[: , i , : , : ], K[i, : , : ])\n",
    "    return res\n",
    "\n",
    "def corr2d_multi_in_out(X, K):\n",
    "    \"\"\"\n",
    "    X: 输入, shape(batch_size, C_in, H, W)\n",
    "    K: 卷积核, shape(C_out, C_in, h, w)\n",
    "    return: 输出, shape(batch_size, C_out, H_out, W_out)\n",
    "    \"\"\"\n",
    "    #print(\"\\ncorr2d_multi_in_out\")\n",
    "    #print(X.shape)  #torch.Size([32, 3, 100, 100])\n",
    "    #print(K.shape)  #torch.Size([32, 3, 3, 3])\n",
    "    #对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K] , dim=1)\n",
    "\n",
    "class MyConv2D(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(MyConv2D, self).__init__()\n",
    "        if isinstance(kernel_size,int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        self.weight = torch.nn.Parameter(torch.randn((out_channels, in_channels)+kernel_size))\n",
    "        self.bias = torch.nn.Parameter(torch.randn(out_channels,1,1))\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: 输入图片, shape(batch_size, C_in, H, W)\n",
    "        \"\"\"\n",
    "        #print(x.shape) #torch.Size([32, 3, 100, 100])\n",
    "        #print(self.weight.shape) #torch.Size([32, 3, 3, 3])\n",
    "        return corr2d_multi_in_out(x, self.weight) + self.bias\n",
    "    \n",
    "class MyConvModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyConvModule, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            MyConv2D(in_channels=3, out_channels=32, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)           \n",
    "        )\n",
    "        self.fc = nn.Linear(32, num_classes) #[32,3]\n",
    " \n",
    "    def forward(self, X):\n",
    "        out = self.conv(X)\n",
    "        #print(out.shape)  #torch.Size([32, 32, 98, 98])\n",
    "        out = nn.functional.avg_pool2d(out, 98)\n",
    "        #print(out.shape) #torch.Size([32, 32, 1, 1])\n",
    "        out = out.squeeze()\n",
    "        #print(out.shape) #torch.Size([32, 32])\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T07:47:56.259045Z",
     "start_time": "2020-08-14T07:47:55.976181Z"
    }
   },
   "outputs": [],
   "source": [
    "#训练函数\n",
    "def train_epoch(net, data_loader):\n",
    "    \n",
    "    net.train()\n",
    "    train_batch_num = len(data_loader)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    sample_num = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        print(output)\n",
    "        loss = criterion(output, target)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        prediction = torch.argmax(output, 1)\n",
    "        correct += (prediction == target).sum().item()\n",
    "        sample_num += len(prediction)\n",
    "        print(batch_idx)\n",
    "        print(total_loss,correct/sample_num)\n",
    "    \n",
    "    loss = total_loss / train_batch_num\n",
    "    acc = correct / sample_num\n",
    "    return loss, acc\n",
    "\n",
    "#测试函数\n",
    "def test_epoch(net, data_loader):\n",
    "    \n",
    "    net.eval()\n",
    "    test_batch_num = len(data_loader)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    sample_num = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            prediction = torch.argmax(output, 1)\n",
    "            correct += (prediction == target).sum().item()\n",
    "            sample_num += len(prediction)\n",
    "            print(batch_idx)\n",
    "            print(total_loss,correct/sample_num)\n",
    "    \n",
    "    loss = total_loss / train_batch_num\n",
    "    acc = correct / sample_num\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-14T07:47:56.909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212],\n",
      "        [ 0.0851,  0.2599, -0.1212]], grad_fn=<AddmmBackward>)\n",
      "tensor(1.1174, grad_fn=<NllLossBackward>)\n",
      "0\n",
      "1.1174176931381226 0.34375\n",
      "tensor([[ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023],\n",
      "        [ 0.0750,  0.2410, -0.1023]], grad_fn=<AddmmBackward>)\n",
      "tensor(1.1244, grad_fn=<NllLossBackward>)\n",
      "1\n",
      "2.2418476343154907 0.3125\n",
      "tensor([[ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868],\n",
      "        [ 0.0604,  0.2261, -0.0868]], grad_fn=<AddmmBackward>)\n",
      "tensor(1.1273, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "num_epoch = 1\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "\n",
    "#划分数据集\n",
    "train_dataset = torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=0)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_features,test_labels)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "net = MyConvModule()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "train_loss_sum = []\n",
    "train_acc_sum = []\n",
    "test_loss_sum = []\n",
    "test_acc_sum = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(net, data_loader=train_iter)\n",
    "    test_loss, test_acc = test_epoch(net, data_loader=test_iter)\n",
    "    \n",
    "    train_loss_sum.append(train_loss)\n",
    "    train_acc_sum.append(train_acc)\n",
    "    test_loss_sum.append(test_loss)\n",
    "    test_acc_sum.append(test_acc)\n",
    "    \n",
    "    print('epoch %d, train_loss %f, test_loss %f, train_acc %f, test_acc %f' % \n",
    "          (epoch+1, train_loss, test_loss, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pytorch_envs]",
   "language": "python",
   "name": "conda-env-Pytorch_envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
