{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T05:27:33.313060Z",
     "start_time": "2020-08-14T05:27:29.051112Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T05:28:51.006078Z",
     "start_time": "2020-08-14T05:27:33.345479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([950, 3, 100, 100])\n",
      "torch.Size([407, 3, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "# 处理客车数据，总共218张，前153张为训练集，后65张为测试集\n",
    "\n",
    "# =================== 训练集 =================== #\n",
    "path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\bus\\\\bus001.jpg\"\n",
    "train_features = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "for i in range(2,10):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\bus\\\\bus00\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    train_features = torch.cat((train_features,img), dim=0)\n",
    "for i in range(10,100):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\bus\\\\bus0\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    train_features = torch.cat((train_features,img), dim=0)\n",
    "for i in range(100,154):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\bus\\\\bus\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    train_features = torch.cat((train_features,img), dim=0)\n",
    "\n",
    "# =================== 测试集 =================== #\n",
    "path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\bus\\\\bus154.jpg\"\n",
    "test_features = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "\n",
    "for i in range(155,219):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\bus\\\\bus\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    test_features = torch.cat((test_features,img), dim=0)\n",
    "\n",
    "\n",
    "# 处理汽车数据，总共779张，前545张为训练集，后234张为测试集\n",
    "\n",
    "# =================== 训练集 =================== #\n",
    "for i in range(1,10):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\car\\\\car00\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    train_features = torch.cat((train_features,img), dim=0)\n",
    "for i in range(10,100):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\car\\\\car0\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    train_features = torch.cat((train_features,img), dim=0)\n",
    "for i in range(100,546):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\car\\\\car\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    train_features = torch.cat((train_features,img), dim=0)\n",
    "\n",
    "# =================== 测试集 =================== #\n",
    "for i in range(546,780):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\car\\\\car\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    test_features = torch.cat((test_features,img), dim=0)\n",
    "\n",
    "# 处理货车数据，总共360张，前252张为训练集，后108张为测试集\n",
    "\n",
    "# =================== 训练集 =================== #\n",
    "for i in range(1,10):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\truck\\\\truck00\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    train_features = torch.cat((train_features,img), dim=0)\n",
    "for i in range(10,100):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\truck\\\\truck0\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    train_features = torch.cat((train_features,img), dim=0)\n",
    "for i in range(100,253):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\truck\\\\truck\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    train_features = torch.cat((train_features,img), dim=0)\n",
    "\n",
    "# =================== 测试集 =================== #\n",
    "for i in range(253,361):\n",
    "    path = \"D:\\课件-研究生\\深度学习_万怀宇\\实验3\\车辆分类数据集\\\\truck\\\\truck\"+ str(i) + \".jpg\"\n",
    "    img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "    test_features = torch.cat((test_features,img), dim=0)\n",
    "\n",
    "train_features = train_features.permute(0,3,2,1)\n",
    "test_features = test_features.permute(0,3,2,1)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T05:28:51.220688Z",
     "start_time": "2020-08-14T05:28:51.186773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([950])\n",
      "torch.Size([407])\n"
     ]
    }
   ],
   "source": [
    "# =================== 训练集标签 =================== #\n",
    "train_labels = torch.zeros(153).long()\n",
    "train_labels = torch.cat((train_labels,torch.ones(545).long()), dim=0)\n",
    "train_labels = torch.cat((train_labels,torch.ones(252).long()+1), dim=0)\n",
    "print(train_labels.shape)\n",
    "\n",
    "# =================== 测试集标签 =================== #\n",
    "test_labels = torch.zeros(65).long()\n",
    "test_labels = torch.cat((test_labels,torch.ones(234).long()), dim=0)\n",
    "test_labels = torch.cat((test_labels,torch.ones(108).long()+1), dim=0)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T05:28:51.560533Z",
     "start_time": "2020-08-14T05:28:51.352679Z"
    }
   },
   "outputs": [],
   "source": [
    "#自定义卷积层\n",
    "\n",
    "def corr2d(X, K):\n",
    "    \"\"\"\n",
    "    X: 输入, shape(batch_size, H, W)\n",
    "    K: 卷积核,shape(k_h, k_w)\n",
    "    \"\"\"\n",
    "    batch_size, H, W = X.shape\n",
    "    #print(\"\\ncorr2d:\")\n",
    "    #print(X.shape)\n",
    "    #print(batch_size, H, W)\n",
    "    k_h, k_w = K.shape\n",
    "    #初始化结果矩阵\n",
    "    Y = torch.zeros((batch_size, H-k_h+1, W-k_w+1))\n",
    "    for i in range(Y.shape[1]):\n",
    "        for j in range(Y.shape[2]):\n",
    "            Y[:,i,j] = (X[: , i:i+k_h , j:j+k_w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    \"\"\"\n",
    "    X: 输入, shape(batch_size, C_in, H, W)\n",
    "    K: 卷积核, shape(C_in, k_h, k_w)\n",
    "    return: 输出, shape(batch_size, H_out, W_out)\n",
    "    \"\"\"\n",
    "    #print(\"\\ncorr2d_multi_in\")\n",
    "    #print(X.shape)\n",
    "    #print(K.shape)\n",
    "    res = corr2d(X[: , 0 , : , : ], K[0, : , : ])\n",
    "    for i in range(1, X.shape[1]):\n",
    "        res += corr2d(X[: , i , : , : ], K[i, : , : ])\n",
    "    return res\n",
    "\n",
    "def corr2d_multi_in_out(X, K):\n",
    "    \"\"\"\n",
    "    X: 输入, shape(batch_size, C_in, H, W)\n",
    "    K: 卷积核, shape(C_out, C_in, h, w)\n",
    "    return: 输出, shape(batch_size, C_out, H_out, W_out)\n",
    "    \"\"\"\n",
    "    #print(\"\\ncorr2d_multi_in_out\")\n",
    "    #print(X.shape)\n",
    "    #print(K.shape)\n",
    "    #对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K] , dim=1)\n",
    "\n",
    "class MyConv2D(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(MyConv2D, self).__init__()\n",
    "        if isinstance(kernel_size,int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        self.weight = torch.nn.Parameter(torch.randn((out_channels, in_channels)+kernel_size))\n",
    "        self.bias = torch.nn.Parameter(torch.randn(out_channels,1,1))\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: 输入图片, shape(batch_size, C_in, H, W)\n",
    "        \"\"\"\n",
    "        #print(x.shape) torch.Size([32, 3, 100, 100])\n",
    "        #print(self.weight.shape) torch.Size([32, 3, 3, 3])\n",
    "        return corr2d_multi_in_out(x, self.weight) + self.bias\n",
    "    \n",
    "class MyConvModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyConvModule, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            MyConv2D(in_channels=3, out_channels=32, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)           \n",
    "        )\n",
    "        self.fc = nn.Linear(32, num_classes) #[32,3]\n",
    " \n",
    "    def forward(self, X):\n",
    "        out = self.conv(X)\n",
    "        #print(out.shape)  torch.Size([32, 32, 98, 98])\n",
    "        out = nn.functional.avg_pool2d(out, 98)\n",
    "        #print(out.shape) torch.Size([32, 32, 3, 3])\n",
    "        out = out.squeeze()\n",
    "        #print(out.shape) torch.Size([32, 32, 3, 3])\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T05:28:51.779218Z",
     "start_time": "2020-08-14T05:28:51.677362Z"
    }
   },
   "outputs": [],
   "source": [
    "#训练函数\n",
    "def train_epoch(net, data_loader):\n",
    "    \n",
    "    net.train()\n",
    "    train_batch_num = len(data_loader)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    sample_num = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        prediction = torch.argmax(output, 1)\n",
    "        correct += (prediction == target).sum().item()\n",
    "        sample_num += len(prediction)\n",
    "    \n",
    "    loss = total_loss / train_batch_num\n",
    "    acc = correct / sample_num\n",
    "    return loss, acc\n",
    "\n",
    "#测试函数\n",
    "def test_epoch(net, data_loader):\n",
    "    \n",
    "    net.eval()\n",
    "    test_batch_num = len(data_loader)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    sample_num = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            prediction = torch.argmax(output, 1)\n",
    "            correct += (prediction == target).sum().item()\n",
    "            sample_num += len(prediction)\n",
    "    \n",
    "    loss = total_loss / train_batch_num\n",
    "    acc = correct / sample_num\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-14T05:27:36.393Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "num_epoch = 5\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "#划分数据集\n",
    "train_dataset = torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=0)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_features,test_labels)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "net = MyConvModule()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "train_loss_sum = []\n",
    "train_acc_sum = []\n",
    "test_loss_sum = []\n",
    "test_acc_sum = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(net, data_loader=train_iter)\n",
    "    test_loss, test_acc = test_epoch(net, data_loader=test_iter)\n",
    "    \n",
    "    train_loss_sum.append(train_loss)\n",
    "    train_acc_sum.append(train_acc)\n",
    "    test_loss_sum.append(test_loss)\n",
    "    test_acc_sum.append(test_acc)\n",
    "    \n",
    "    print('epoch %d, train_loss %f, test_loss %f, train_acc %f, test_acc %f' % \n",
    "          (epoch+1, train_loss, test_loss, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T17:11:12.484966Z",
     "start_time": "2020-08-13T17:11:12.470266Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.tensor([[[0, 1], [2, 3]],[[4, 5], [6, 7]],[[8, 9], [10, 11]]])\n",
    "y = X.view(2,2,3).permute(2, 1, 0)\n",
    "y = y.view(1,3,2,2)\n",
    "y = torch.cat((y,y+4),dim=0)\n",
    "print(y.shape)\n",
    "print(y[0, :, :, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 处理客车数据，总共218张，前153张为训练集，后65张为测试集\n",
    "\n",
    "# # =================== 训练集 =================== #\n",
    "# path = \"data/bus/bus001.jpg\"\n",
    "# train_features = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "# for i in range(2,10):\n",
    "#     path = \"data/bus/bus00\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     train_features = torch.cat((train_features,img), dim=0)\n",
    "# for i in range(10,100):\n",
    "#     path = \"data/bus/bus0\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     train_features = torch.cat((train_features,img), dim=0)\n",
    "# for i in range(100,154):\n",
    "#     path = \"data/bus/bus\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     train_features = torch.cat((train_features,img), dim=0)\n",
    "\n",
    "# # =================== 测试集 =================== #\n",
    "# path = \"data/bus/bus154.jpg\"\n",
    "# test_features = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "\n",
    "# for i in range(155,219):\n",
    "#     path = \"data/bus/bus\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     test_features = torch.cat((test_features,img), dim=0)\n",
    "\n",
    "\n",
    "# # 处理汽车数据，总共779张，前545张为训练集，后234张为测试集\n",
    "\n",
    "# # =================== 训练集 =================== #\n",
    "# for i in range(1,10):\n",
    "#     path = \"data/car/car00\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     train_features = torch.cat((train_features,img), dim=0)\n",
    "# for i in range(10,100):\n",
    "#     path = \"data/car/car0\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     train_features = torch.cat((train_features,img), dim=0)\n",
    "# for i in range(100,546):\n",
    "#     path = \"data/car/car\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     train_features = torch.cat((train_features,img), dim=0)\n",
    "\n",
    "# # =================== 测试集 =================== #\n",
    "# for i in range(546,780):\n",
    "#     path = \"data/car/car\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     test_features = torch.cat((test_features,img), dim=0)\n",
    "\n",
    "# # 处理货车数据，总共360张，前252张为训练集，后108张为测试集\n",
    "\n",
    "# # =================== 训练集 =================== #\n",
    "# for i in range(1,10):\n",
    "#     path = \"data/truck/truck00\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     train_features = torch.cat((train_features,img), dim=0)\n",
    "# for i in range(10,100):\n",
    "#     path = \"data/truck/truck0\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     train_features = torch.cat((train_features,img), dim=0)\n",
    "# for i in range(100,253):\n",
    "#     path = \"data/truck/truck\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     train_features = torch.cat((train_features,img), dim=0)\n",
    "\n",
    "# # =================== 测试集 =================== #\n",
    "# for i in range(253,361):\n",
    "#     path = \"data/truck/truck\"+ str(i) + \".jpg\"\n",
    "#     img = torch.Tensor(np.array(Image.open(path).resize((100,100),Image.ANTIALIAS))/255).view(1, 100, 100, 3)\n",
    "#     test_features = torch.cat((test_features,img), dim=0)\n",
    "\n",
    "# train_features = train_features.permute(0,3,2,1)\n",
    "# test_features = test_features.permute(0,3,2,1)\n",
    "# print(train_features.shape)\n",
    "# print(test_features.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pytorch_envs]",
   "language": "python",
   "name": "conda-env-Pytorch_envs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
